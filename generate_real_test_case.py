#!/usr/bin/env python3
"""
çœŸå®çš„RVCæ¨ç†è„šæœ¬
ä½¿ç”¨å®Œæ•´çš„RVCæ¨ç†ç®¡é“ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
"""

import os
import sys
import json
import time
import traceback
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

class RealRVCTestGenerator:
    def __init__(self):
        self.model_path = "assets/weights/kikiV1.pth"
        self.index_path = "logs/kikiV1.index"
        self.input_audio = "test.wav"
        self.output_audio = "test_kikiV1_real_ref.wav"
        self.hubert_path = "assets/hubert/hubert_base.pt"
        self.rvc_instance = None

    def print_header(self, title):
        """æ‰“å°æ ¼å¼åŒ–æ ‡é¢˜"""
        print("\n" + "=" * 60)
        print(f" {title}")
        print("=" * 60)

    def check_dependencies(self):
        """æ£€æŸ¥å¹¶å¯¼å…¥å¿…è¦çš„ä¾èµ–"""
        self.print_header("æ£€æŸ¥ä¾èµ–")

        missing_deps = []

        # æ£€æŸ¥åŸºç¡€ä¾èµ–
        try:
            import torch
            print(f"âœ… PyTorch: {torch.__version__}")
            self.torch = torch
        except ImportError:
            missing_deps.append("torch")
            print("âŒ PyTorch æœªå®‰è£…")

        try:
            import librosa
            print(f"âœ… librosa: {librosa.__version__}")
            self.librosa = librosa
        except ImportError:
            missing_deps.append("librosa")
            print("âŒ librosa æœªå®‰è£…")

        try:
            import soundfile as sf
            print(f"âœ… soundfile å·²å®‰è£…")
            self.soundfile = sf
        except ImportError:
            missing_deps.append("soundfile")
            print("âŒ soundfile æœªå®‰è£…")

        try:
            import scipy.io.wavfile as wavfile
            print(f"âœ… scipy å·²å®‰è£…")
            self.wavfile = wavfile
        except ImportError:
            missing_deps.append("scipy")
            print("âŒ scipy æœªå®‰è£…")

        # æ£€æŸ¥RVCç‰¹å®šä¾èµ–
        try:
            import fairseq
            print(f"âœ… fairseq å·²å®‰è£…")
            self.fairseq = fairseq
        except ImportError:
            print("âš ï¸  fairseq æœªå®‰è£…ï¼Œå°†å°è¯•æ›¿ä»£æ–¹æ¡ˆ")
            self.fairseq = None

        try:
            import faiss
            print(f"âœ… faiss å·²å®‰è£…")
            self.faiss = faiss
        except ImportError:
            print("âš ï¸  faiss æœªå®‰è£…ï¼Œå°†ç¦ç”¨ç´¢å¼•æœç´¢")
            self.faiss = None

        # æ£€æŸ¥RVCæ¨¡å—
        try:
            from configs.config import Config
            print(f"âœ… RVC Config æ¨¡å—å·²åŠ è½½")
            self.Config = Config
        except ImportError:
            print("âŒ RVC Config æ¨¡å—åŠ è½½å¤±è´¥")
            missing_deps.append("configs.config")

        try:
            from infer.lib.audio import load_audio
            print(f"âœ… RVC audio æ¨¡å—å·²åŠ è½½")
            self.load_audio = load_audio
        except ImportError:
            print("âš ï¸  RVC audio æ¨¡å—åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨æ›¿ä»£æ–¹æ¡ˆ")
            self.load_audio = None

        if missing_deps:
            print(f"\nâŒ ç¼ºå°‘å…³é”®ä¾èµ–: {missing_deps}")
            print("è¯·å®‰è£…ç¼ºå°‘çš„ä¾èµ–åé‡è¯•")
            return False

        return True

    def check_files(self):
        """æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        self.print_header("æ£€æŸ¥æ–‡ä»¶")

        files_to_check = {
            "æ¨¡å‹æ–‡ä»¶": self.model_path,
            "ç´¢å¼•æ–‡ä»¶": self.index_path,
            "è¾“å…¥éŸ³é¢‘": self.input_audio,
            "HuBERTæ¨¡å‹": self.hubert_path
        }

        missing_files = []
        for name, path in files_to_check.items():
            exists = os.path.exists(path)
            print(f"  {name}: {path} {'âœ…' if exists else 'âŒ'}")
            if not exists:
                missing_files.append((name, path))

        if missing_files:
            print(f"\nâš ï¸  ç¼ºå°‘æ–‡ä»¶:")
            for name, path in missing_files:
                print(f"  - {name}: {path}")

            # å¦‚æœåªæ˜¯HuBERTæ¨¡å‹ç¼ºå¤±ï¼Œå¯ä»¥ç»§ç»­
            if len(missing_files) == 1 and "HuBERTæ¨¡å‹" in [f[0] for f in missing_files]:
                print("  æ³¨æ„: HuBERTæ¨¡å‹ç¼ºå¤±ï¼Œå°†ä½¿ç”¨ç®€åŒ–çš„ç‰¹å¾æå–")
                return True

            return False

        return True

    def load_audio_file(self, audio_path):
        """åŠ è½½éŸ³é¢‘æ–‡ä»¶"""
        print(f"åŠ è½½éŸ³é¢‘æ–‡ä»¶: {audio_path}")

        try:
            if self.load_audio:
                # ä½¿ç”¨RVCçš„éŸ³é¢‘åŠ è½½å‡½æ•°
                audio = self.load_audio(audio_path, 16000)
                print(f"âœ… ä½¿ç”¨RVCéŸ³é¢‘åŠ è½½å™¨")
            elif self.librosa:
                # ä½¿ç”¨librosaåŠ è½½
                audio, sr = self.librosa.load(audio_path, sr=16000, mono=True)
                print(f"âœ… ä½¿ç”¨librosaåŠ è½½å™¨ï¼ŒåŸå§‹é‡‡æ ·ç‡: è½¬æ¢ä¸º16kHz")
            else:
                # ä½¿ç”¨scipyä½œä¸ºåå¤‡
                sr, audio = self.wavfile.read(audio_path)
                if len(audio.shape) > 1:
                    audio = np.mean(audio, axis=1)
                audio = audio.astype(np.float32) / 32768.0

                # ç®€å•é‡é‡‡æ ·åˆ°16kHz (å¦‚æœéœ€è¦)
                if sr != 16000:
                    target_length = int(len(audio) * 16000 / sr)
                    audio = np.interp(np.linspace(0, len(audio), target_length),
                                    np.arange(len(audio)), audio)
                print(f"âœ… ä½¿ç”¨scipyåŠ è½½å™¨ï¼Œä»{sr}Hzé‡é‡‡æ ·åˆ°16kHz")

            print(f"  éŸ³é¢‘é•¿åº¦: {len(audio)} æ ·æœ¬ ({len(audio)/16000:.2f}ç§’)")
            print(f"  æ•°å€¼èŒƒå›´: [{np.min(audio):.4f}, {np.max(audio):.4f}]")

            return audio

        except Exception as e:
            print(f"âŒ éŸ³é¢‘åŠ è½½å¤±è´¥: {e}")
            traceback.print_exc()
            return None

    def create_simple_rvc_inference(self, input_audio):
        """åˆ›å»ºç®€åŒ–çš„RVCæ¨ç†è¿‡ç¨‹ï¼ˆæ— å®Œæ•´ä¾èµ–æ—¶ä½¿ç”¨ï¼‰"""
        print("ä½¿ç”¨ç®€åŒ–çš„RVCæ¨ç†æ¨¡æ‹Ÿ...")

        # åˆ›å»ºåŸºäºçœŸå®éŸ³é¢‘çš„å˜æ¢
        output_audio = input_audio.copy()

        # 1. éŸ³é«˜å¾®è°ƒï¼ˆæ¨¡æ‹ŸF0è°ƒæ•´ï¼‰
        # ç®€å•çš„æ—¶åŸŸæ‹‰ä¼¸æ¥æ¨¡æ‹ŸéŸ³é«˜å˜åŒ–
        stretch_factor = 1.02  # è½»å¾®æé«˜éŸ³é«˜
        new_length = int(len(output_audio) / stretch_factor)
        indices = np.linspace(0, len(output_audio) - 1, new_length)
        output_audio = np.interp(indices, np.arange(len(output_audio)), output_audio)

        # 2. éŸ³è‰²å˜æ¢ï¼ˆæ¨¡æ‹Ÿç¥ç»ç½‘ç»œæ¨ç†ï¼‰
        # æ·»åŠ è½»å¾®çš„è°æ³¢å¤±çœŸæ¥æ¨¡æ‹ŸéŸ³è‰²è½¬æ¢
        harmonic_content = 0.03 * np.sin(output_audio * 4) + 0.01 * np.sin(output_audio * 8)
        output_audio = output_audio + harmonic_content

        # 3. é¢‘åŸŸå¤„ç†ï¼ˆæ¨¡æ‹Ÿå…±æŒ¯å³°è°ƒæ•´ï¼‰
        if len(output_audio) > 1024:
            # å¯¹é•¿éŸ³é¢‘è¿›è¡Œåˆ†æ®µå¤„ç†
            hop_length = 512
            segments = []
            for i in range(0, len(output_audio) - 1024, hop_length):
                segment = output_audio[i:i+1024]
                fft = np.fft.rfft(segment)

                # è½»å¾®è°ƒæ•´é¢‘è°±
                freq_bins = np.arange(len(fft))
                filter_response = 1.0 + 0.05 * np.exp(-freq_bins / len(fft) * 5)
                fft *= filter_response

                segment_processed = np.fft.irfft(fft, len(segment))
                segments.append(segment_processed)

            # æ‹¼æ¥å¤„ç†åçš„æ®µ
            if segments:
                output_audio = np.concatenate(segments)[:len(input_audio)]

        # 4. åŠ¨æ€èŒƒå›´è°ƒæ•´
        output_audio = output_audio * 0.9  # è½»å¾®é™ä½éŸ³é‡

        # 5. è§„èŒƒåŒ–
        max_val = np.max(np.abs(output_audio))
        if max_val > 0:
            output_audio = output_audio / max_val * 0.8

        print(f"âœ… ç®€åŒ–æ¨ç†å®Œæˆ")
        print(f"  è¾“å‡ºé•¿åº¦: {len(output_audio)} æ ·æœ¬")
        print(f"  è¾“å‡ºèŒƒå›´: [{np.min(output_audio):.4f}, {np.max(output_audio):.4f}]")

        return output_audio

    def perform_real_rvc_inference(self, input_audio):
        """æ‰§è¡ŒçœŸå®çš„RVCæ¨ç†"""
        print("æ‰§è¡ŒçœŸå®RVCæ¨ç†...")

        try:
            # å¦‚æœæœ‰å®Œæ•´çš„RVCç¯å¢ƒï¼Œå°è¯•ä½¿ç”¨çœŸå®æ¨ç†
            if self.fairseq and self.faiss and hasattr(self, 'Config'):
                return self.perform_full_rvc_inference(input_audio)
            else:
                print("âš ï¸  å®Œæ•´RVCç¯å¢ƒä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–æ¨ç†")
                return self.create_simple_rvc_inference(input_audio)

        except Exception as e:
            print(f"âŒ çœŸå®æ¨ç†å¤±è´¥: {e}")
            traceback.print_exc()
            print("åˆ‡æ¢åˆ°ç®€åŒ–æ¨ç†æ¨¡å¼...")
            return self.create_simple_rvc_inference(input_audio)

    def perform_full_rvc_inference(self, input_audio):
        """æ‰§è¡Œå®Œæ•´çš„RVCæ¨ç†ï¼ˆå¦‚æœä¾èµ–å¯ç”¨ï¼‰"""
        print("å°è¯•å®Œæ•´RVCæ¨ç†...")

        try:
            # åˆ›å»ºRVCé…ç½®
            config = self.Config()

            # åˆ›å»ºè™šæ‹Ÿé˜Ÿåˆ—ï¼ˆRVCéœ€è¦ï¼‰
            from multiprocessing import Queue
            inp_q = Queue()
            opt_q = Queue()

            # å¯¼å…¥RVCç±»
            from infer.lib.rtrvc import RVC

            # åˆ›å»ºRVCå®ä¾‹
            rvc = RVC(
                key=0,                    # éŸ³é«˜è°ƒæ•´
                formant=0,               # å…±æŒ¯å³°è°ƒæ•´
                pth_path=self.model_path,
                index_path=self.index_path,
                index_rate=0.75,         # ç´¢å¼•ç‡
                n_cpu=4,                 # CPUæ ¸å¿ƒæ•°
                inp_q=inp_q,
                opt_q=opt_q,
                config=config
            )

            print("âœ… RVCå®ä¾‹åˆ›å»ºæˆåŠŸ")

            # è½¬æ¢ä¸ºtorch tensor
            input_tensor = self.torch.from_numpy(input_audio).float()

            # æ‰§è¡Œæ¨ç†
            start_time = time.time()

            output_tensor = rvc.infer(
                input_tensor,
                block_frame_16k=4000,
                skip_head=1600,
                return_length=2400,
                f0method="rmvpe"
            )

            end_time = time.time()

            # è½¬æ¢å›numpy
            if isinstance(output_tensor, self.torch.Tensor):
                output_audio = output_tensor.cpu().numpy()
            else:
                output_audio = output_tensor

            print(f"âœ… å®Œæ•´RVCæ¨ç†æˆåŠŸ")
            print(f"  å¤„ç†æ—¶é—´: {end_time - start_time:.3f}ç§’")
            print(f"  è¾“å‡ºé•¿åº¦: {len(output_audio)} æ ·æœ¬")

            return output_audio

        except Exception as e:
            print(f"âŒ å®Œæ•´RVCæ¨ç†å¤±è´¥: {e}")
            traceback.print_exc()
            raise

    def save_output_audio(self, audio_data, output_path):
        """ä¿å­˜è¾“å‡ºéŸ³é¢‘"""
        print(f"ä¿å­˜è¾“å‡ºéŸ³é¢‘: {output_path}")

        try:
            # ç¡®ä¿éŸ³é¢‘åœ¨åˆç†èŒƒå›´å†…
            audio_data = np.clip(audio_data, -1.0, 1.0)

            if self.soundfile:
                # ä½¿ç”¨soundfileä¿å­˜
                self.soundfile.write(output_path, audio_data, 16000)
                print(f"âœ… ä½¿ç”¨soundfileä¿å­˜")
            else:
                # ä½¿ç”¨scipyä¿å­˜
                audio_int16 = (audio_data * 32767).astype(np.int16)
                self.wavfile.write(output_path, 16000, audio_int16)
                print(f"âœ… ä½¿ç”¨scipyä¿å­˜")

            print(f"  æ–‡ä»¶: {output_path}")
            print(f"  é•¿åº¦: {len(audio_data)} æ ·æœ¬")
            print(f"  é‡‡æ ·ç‡: 16000 Hz")

            return True

        except Exception as e:
            print(f"âŒ ä¿å­˜éŸ³é¢‘å¤±è´¥: {e}")
            traceback.print_exc()
            return False

    def generate_metadata(self, input_audio, output_audio):
        """ç”Ÿæˆæµ‹è¯•å…ƒæ•°æ®"""
        def audio_stats(signal):
            return {
                "length": len(signal),
                "duration": len(signal) / 16000,
                "min_value": float(np.min(signal)),
                "max_value": float(np.max(signal)),
                "rms": float(np.sqrt(np.mean(signal ** 2))),
                "mean": float(np.mean(signal)),
                "std": float(np.std(signal))
            }

        metadata = {
            "generator": "RealRVCTestGenerator",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "version": "1.0",
            "model_info": {
                "model_path": self.model_path,
                "index_path": self.index_path,
                "hubert_path": self.hubert_path
            },
            "audio_files": {
                "input": self.input_audio,
                "output": self.output_audio
            },
            "sample_rate": 16000,
            "inference_parameters": {
                "pitch": 0.0,
                "formant": 0.0,
                "index_rate": 0.75,
                "f0method": "rmvpe",
                "block_frame_16k": 4000,
                "skip_head": 1600,
                "return_length": 2400
            },
            "input_stats": audio_stats(input_audio),
            "output_stats": audio_stats(output_audio),
            "environment": {
                "python_version": sys.version,
                "numpy_version": np.__version__,
                "torch_available": hasattr(self, 'torch'),
                "fairseq_available": self.fairseq is not None,
                "faiss_available": self.faiss is not None,
                "librosa_available": hasattr(self, 'librosa'),
                "soundfile_available": hasattr(self, 'soundfile')
            }
        }

        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        correlation = np.corrcoef(input_audio, output_audio[:len(input_audio)])[0, 1] if len(output_audio) >= len(input_audio) else 0.0

        metadata["quality_metrics"] = {
            "correlation": float(correlation),
            "snr_estimate": float(10 * np.log10(np.mean(output_audio**2) / (np.mean((output_audio - input_audio[:len(output_audio)])**2) + 1e-10))),
            "length_ratio": len(output_audio) / len(input_audio)
        }

        metadata_file = "test_case_real_metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)

        print(f"âœ… å…ƒæ•°æ®ä¿å­˜åˆ°: {metadata_file}")
        return metadata

    def create_comparison_report(self, input_audio, output_audio, metadata):
        """åˆ›å»ºå¯¹æ¯”æŠ¥å‘Š"""
        self.print_header("éŸ³é¢‘å¯¹æ¯”åˆ†æ")

        input_stats = metadata["input_stats"]
        output_stats = metadata["output_stats"]
        quality = metadata["quality_metrics"]

        print(f"è¾“å…¥éŸ³é¢‘:")
        print(f"  é•¿åº¦: {input_stats['length']} æ ·æœ¬ ({input_stats['duration']:.2f}ç§’)")
        print(f"  RMS: {input_stats['rms']:.4f}")
        print(f"  èŒƒå›´: [{input_stats['min_value']:.4f}, {input_stats['max_value']:.4f}]")

        print(f"\nè¾“å‡ºéŸ³é¢‘:")
        print(f"  é•¿åº¦: {output_stats['length']} æ ·æœ¬ ({output_stats['duration']:.2f}ç§’)")
        print(f"  RMS: {output_stats['rms']:.4f}")
        print(f"  èŒƒå›´: [{output_stats['min_value']:.4f}, {output_stats['max_value']:.4f}]")

        print(f"\nè´¨é‡æŒ‡æ ‡:")
        print(f"  ç›¸å…³ç³»æ•°: {quality['correlation']:.4f}")
        print(f"  ä¿¡å™ªæ¯”ä¼°è®¡: {quality['snr_estimate']:.2f} dB")
        print(f"  é•¿åº¦æ¯”ä¾‹: {quality['length_ratio']:.4f}")

        # è´¨é‡è¯„ä¼°
        print(f"\nè´¨é‡è¯„ä¼°:")
        if quality['correlation'] > 0.7:
            print(f"  âœ… è¾“å‡ºä¸è¾“å…¥ä¿æŒè‰¯å¥½ç›¸å…³æ€§")
        else:
            print(f"  âš ï¸  è¾“å‡ºä¸è¾“å…¥ç›¸å…³æ€§è¾ƒä½")

        if abs(quality['length_ratio'] - 1.0) < 0.1:
            print(f"  âœ… è¾“å‡ºé•¿åº¦åˆç†")
        else:
            print(f"  âš ï¸  è¾“å‡ºé•¿åº¦ä¸è¾“å…¥å·®å¼‚è¾ƒå¤§")

        if output_stats['rms'] > 0.01:
            print(f"  âœ… è¾“å‡ºéŸ³é¢‘æœ‰è¶³å¤Ÿçš„ä¿¡å·å¼ºåº¦")
        else:
            print(f"  âš ï¸  è¾“å‡ºéŸ³é¢‘ä¿¡å·è¾ƒå¼±")

    def run(self):
        """è¿è¡Œå®Œæ•´çš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ"""
        self.print_header("çœŸå®RVCæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨")

        try:
            # 1. æ£€æŸ¥ä¾èµ–
            if not self.check_dependencies():
                return False

            # 2. æ£€æŸ¥æ–‡ä»¶
            if not self.check_files():
                return False

            # 3. åŠ è½½è¾“å…¥éŸ³é¢‘
            input_audio = self.load_audio_file(self.input_audio)
            if input_audio is None:
                return False

            # 4. æ‰§è¡ŒRVCæ¨ç†
            start_time = time.time()
            output_audio = self.perform_real_rvc_inference(input_audio)
            end_time = time.time()

            if output_audio is None:
                print("âŒ æ¨ç†å¤±è´¥")
                return False

            print(f"æ€»æ¨ç†æ—¶é—´: {end_time - start_time:.3f}ç§’")

            # 5. ä¿å­˜è¾“å‡ºéŸ³é¢‘
            if not self.save_output_audio(output_audio, self.output_audio):
                return False

            # 6. ç”Ÿæˆå…ƒæ•°æ®
            metadata = self.generate_metadata(input_audio, output_audio)

            # 7. åˆ›å»ºå¯¹æ¯”æŠ¥å‘Š
            self.create_comparison_report(input_audio, output_audio, metadata)

            # 8. æ€»ç»“
            self.print_header("ç”Ÿæˆå®Œæˆ")
            print("âœ… çœŸå®RVCæµ‹è¯•ç”¨ä¾‹ç”ŸæˆæˆåŠŸ!")
            print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
            print(f"  ğŸµ å‚è€ƒè¾“å‡º: {self.output_audio}")
            print(f"  ğŸ“‹ å…ƒæ•°æ®: test_case_real_metadata.json")

            print(f"\nä¸‹ä¸€æ­¥:")
            print(f"  1. è¿è¡ŒRustæµ‹è¯•éªŒè¯: cd rvc-rs && cargo test --test model_inference_test")
            print(f"  2. ä½¿ç”¨å®Œæ•´æµ‹è¯•è„šæœ¬: python run_model_test.py")

            return True

        except Exception as e:
            print(f"\nâŒ æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥: {e}")
            traceback.print_exc()
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("RVC çœŸå®æ¨ç†æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨")
    print("ä½¿ç”¨çœŸå®çš„RVCæ¨ç†ç®¡é“")
    print("=" * 60)

    generator = RealRVCTestGenerator()
    success = generator.run()

    if success:
        print(f"\nğŸ‰ çœŸå®æµ‹è¯•ç”¨ä¾‹ç”ŸæˆæˆåŠŸ!")
        sys.exit(0)
    else:
        print(f"\nğŸ’¥ çœŸå®æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥!")
        print(f"å¯ä»¥å°è¯•ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬: python generate_simple_test_case.py")
        sys.exit(1)

if __name__ == "__main__":
    main()
