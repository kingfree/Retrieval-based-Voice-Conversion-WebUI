#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆRVCæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨
é¿å…å¤æ‚ä¾èµ–ï¼Œä½¿ç”¨åˆæˆæ•°æ®æ¨¡æ‹ŸRVCæ¨ç†è¿‡ç¨‹
"""

import os
import sys
import json
import numpy as np
import time
from pathlib import Path

class SimpleTestCaseGenerator:
    def __init__(self):
        self.model_path = "assets/weights/kikiV1.pth"
        self.index_path = "logs/kikiV1.index"
        self.input_audio = "test.wav"
        self.output_audio = "test_kikiV1_ref.wav"

    def print_header(self, title):
        """æ‰“å°æ ¼å¼åŒ–æ ‡é¢˜"""
        print("\n" + "=" * 50)
        print(f" {title}")
        print("=" * 50)

    def check_files(self):
        """æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        files_to_check = [
            self.model_path,
            self.index_path,
            self.input_audio
        ]

        print("æ–‡ä»¶æ£€æŸ¥:")
        missing_files = []
        for file_path in files_to_check:
            exists = os.path.exists(file_path)
            print(f"  {file_path}: {'âœ…' if exists else 'âŒ'}")
            if not exists:
                missing_files.append(file_path)

        if missing_files:
            print(f"\nâš ï¸  ç¼ºå°‘æ–‡ä»¶: {missing_files}")
            print("æ³¨æ„: è¿™æ˜¯ç®€åŒ–ç‰ˆç”Ÿæˆå™¨ï¼Œå°†ä½¿ç”¨åˆæˆæ•°æ®")

        return True  # å³ä½¿æ–‡ä»¶ä¸å­˜åœ¨ä¹Ÿç»§ç»­ï¼Œä½¿ç”¨åˆæˆæ•°æ®

    def create_synthetic_input(self):
        """åˆ›å»ºåˆæˆè¾“å…¥éŸ³é¢‘æ•°æ®"""
        print("åˆ›å»ºåˆæˆè¾“å…¥éŸ³é¢‘...")

        # ç”Ÿæˆ1ç§’çš„å¤åˆä¿¡å·
        sample_rate = 16000
        duration = 1.0
        t = np.linspace(0, duration, int(sample_rate * duration), dtype=np.float32)

        # åŸºé¢‘440Hz + æ³›éŸ³
        fundamental = 440.0
        signal = (
            0.5 * np.sin(2 * np.pi * fundamental * t) +      # åŸºé¢‘
            0.2 * np.sin(2 * np.pi * fundamental * 2 * t) +  # 2æ¬¡è°æ³¢
            0.1 * np.sin(2 * np.pi * fundamental * 3 * t) +  # 3æ¬¡è°æ³¢
            0.05 * np.random.normal(0, 0.1, len(t))          # è½»å¾®å™ªå£°
        )

        # æ·»åŠ åŒ…ç»œï¼ˆæ¸å…¥æ¸å‡ºï¼‰
        envelope = np.ones_like(signal)
        fade_samples = int(0.05 * sample_rate)  # 50msæ¸å˜
        envelope[:fade_samples] = np.linspace(0, 1, fade_samples)
        envelope[-fade_samples:] = np.linspace(1, 0, fade_samples)
        signal *= envelope

        # è§„èŒƒåŒ–
        signal = signal / np.max(np.abs(signal)) * 0.8

        print(f"âœ… åˆæˆè¾“å…¥éŸ³é¢‘åˆ›å»ºå®Œæˆ")
        print(f"  é‡‡æ ·ç‡: {sample_rate} Hz")
        print(f"  é•¿åº¦: {len(signal)} æ ·æœ¬ ({duration:.1f}ç§’)")
        print(f"  æ•°å€¼èŒƒå›´: [{np.min(signal):.4f}, {np.max(signal):.4f}]")

        return signal, sample_rate

    def simulate_rvc_inference(self, input_audio, sample_rate):
        """æ¨¡æ‹ŸRVCæ¨ç†è¿‡ç¨‹"""
        print("æ¨¡æ‹ŸRVCæ¨ç†è¿‡ç¨‹...")

        # æ¨¡æ‹Ÿæ¨ç†å‚æ•°
        pitch_shift = 0.0      # éŸ³é«˜è°ƒæ•´ï¼ˆåŠéŸ³ï¼‰
        formant_shift = 0.0    # å…±æŒ¯å³°è°ƒæ•´
        index_rate = 0.75      # ç´¢å¼•ç‡

        print(f"  æ¨ç†å‚æ•°:")
        print(f"    éŸ³é«˜è°ƒæ•´: {pitch_shift} åŠéŸ³")
        print(f"    å…±æŒ¯å³°è°ƒæ•´: {formant_shift}")
        print(f"    ç´¢å¼•ç‡: {index_rate}")

        # æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
        start_time = time.time()
        time.sleep(0.1)  # æ¨¡æ‹Ÿè®¡ç®—æ—¶é—´

        # ç®€å•çš„éŸ³é¢‘å˜æ¢ï¼ˆæ¨¡æ‹Ÿå£°éŸ³è½¬æ¢ï¼‰
        output_audio = input_audio.copy()

        # 1. æ¨¡æ‹ŸéŸ³é«˜è°ƒæ•´ï¼ˆç®€å•çš„é¢‘åŸŸæ“ä½œï¼‰
        if pitch_shift != 0.0:
            # ä½¿ç”¨FFTè¿›è¡Œç®€å•çš„éŸ³é«˜è°ƒæ•´
            fft = np.fft.rfft(output_audio)
            # ç®€å•çš„é¢‘ç‡åç§»ï¼ˆä¸æ˜¯çœŸæ­£çš„éŸ³é«˜è°ƒæ•´ï¼Œä½†è¶³å¤Ÿæµ‹è¯•ï¼‰
            shift_factor = 2 ** (pitch_shift / 12.0)
            # è¿™é‡Œåªæ˜¯æ¨¡æ‹Ÿï¼Œå®é™…éŸ³é«˜è°ƒæ•´æ›´å¤æ‚
            output_audio *= 0.95  # è½»å¾®éŸ³é‡è°ƒæ•´ä½œä¸ºå˜åŒ–çš„æ ‡å¿—

        # 2. æ¨¡æ‹ŸéŸ³è‰²è½¬æ¢ï¼ˆç®€å•çš„æ»¤æ³¢å’Œå¤±çœŸï¼‰
        # æ·»åŠ è½»å¾®çš„è°æ³¢å¤±çœŸ
        output_audio = output_audio + 0.02 * np.sin(output_audio * 8)

        # 3. æ¨¡æ‹Ÿå…±æŒ¯å³°è°ƒæ•´ï¼ˆç®€å•çš„é¢‘åŸŸæ»¤æ³¢ï¼‰
        if formant_shift != 0.0:
            # ç®€å•çš„é¢‘åŸŸå¤„ç†
            fft = np.fft.rfft(output_audio)
            # æ¨¡æ‹Ÿå…±æŒ¯å³°è°ƒæ•´
            freq_bins = np.arange(len(fft))
            formant_filter = 1.0 + 0.1 * formant_shift * np.exp(-freq_bins / len(fft) * 10)
            fft *= formant_filter
            output_audio = np.fft.irfft(fft, len(output_audio))

        # 4. æ¨¡æ‹ŸéŸ³è‰²æ··åˆï¼ˆä½¿ç”¨ç´¢å¼•ç‡ï¼‰
        # åœ¨çœŸå®RVCä¸­ï¼Œè¿™ä¼šæ··åˆåŸå§‹å’Œè½¬æ¢åçš„ç‰¹å¾
        blend_factor = index_rate
        noise_component = 0.01 * np.random.normal(0, 1, len(output_audio))
        output_audio = output_audio * blend_factor + input_audio * (1 - blend_factor) + noise_component

        # è§„èŒƒåŒ–è¾“å‡º
        max_val = np.max(np.abs(output_audio))
        if max_val > 0:
            output_audio = output_audio / max_val * 0.8

        processing_time = time.time() - start_time

        print(f"âœ… æ¨ç†æ¨¡æ‹Ÿå®Œæˆ")
        print(f"  å¤„ç†æ—¶é—´: {processing_time:.3f}ç§’")
        print(f"  è¾“å‡ºé•¿åº¦: {len(output_audio)} æ ·æœ¬")
        print(f"  è¾“å‡ºèŒƒå›´: [{np.min(output_audio):.4f}, {np.max(output_audio):.4f}]")

        return output_audio

    def save_wav_simple(self, filename, audio_data, sample_rate):
        """ç®€å•çš„WAVæ–‡ä»¶ä¿å­˜ï¼ˆä½¿ç”¨numpyæ ¼å¼ï¼‰"""
        try:
            from scipy.io import wavfile
            # è½¬æ¢ä¸º16ä½æ•´æ•°
            audio_int16 = (audio_data * 32767).astype(np.int16)
            wavfile.write(filename, sample_rate, audio_int16)
            print(f"âœ… ä½¿ç”¨scipyä¿å­˜WAVæ–‡ä»¶: {filename}")
            return True
        except ImportError:
            # å¦‚æœscipyä¸å¯ç”¨ï¼Œä¿å­˜ä¸ºnumpyæ•°ç»„
            np.save(filename.replace('.wav', '.npy'), audio_data)
            print(f"âœ… ä¿å­˜ä¸ºnumpyæ•°ç»„: {filename.replace('.wav', '.npy')}")
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return False

    def generate_test_metadata(self, input_audio, output_audio, sample_rate):
        """ç”Ÿæˆæµ‹è¯•å…ƒæ•°æ®"""
        def audio_stats(signal):
            return {
                "length": len(signal),
                "duration": len(signal) / sample_rate,
                "min_value": float(np.min(signal)),
                "max_value": float(np.max(signal)),
                "rms": float(np.sqrt(np.mean(signal ** 2))),
                "mean": float(np.mean(signal))
            }

        metadata = {
            "generator": "SimpleTestCaseGenerator",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "model_path": self.model_path,
            "index_path": self.index_path,
            "input_audio_file": self.input_audio,
            "output_audio_file": self.output_audio,
            "sample_rate": int(sample_rate),
            "parameters": {
                "pitch": 0.0,
                "formant": 0.0,
                "index_rate": 0.75,
                "f0method": "rmvpe"
            },
            "input_stats": audio_stats(input_audio),
            "output_stats": audio_stats(output_audio),
            "processing_info": {
                "synthetic_data": True,
                "note": "This is synthetic test data for Rust implementation validation"
            }
        }

        metadata_file = "test_case_metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)

        print(f"âœ… æµ‹è¯•å…ƒæ•°æ®ä¿å­˜åˆ°: {metadata_file}")
        return metadata

    def create_comparison_report(self, input_audio, output_audio):
        """åˆ›å»ºå¯¹æ¯”æŠ¥å‘Š"""
        print("\néŸ³é¢‘å¯¹æ¯”åˆ†æ:")

        # åŸºç¡€ç»Ÿè®¡å¯¹æ¯”
        input_rms = np.sqrt(np.mean(input_audio ** 2))
        output_rms = np.sqrt(np.mean(output_audio ** 2))

        print(f"  è¾“å…¥RMS: {input_rms:.4f}")
        print(f"  è¾“å‡ºRMS: {output_rms:.4f}")
        print(f"  RMSå˜åŒ–: {((output_rms - input_rms) / input_rms * 100):+.1f}%")

        # ç›¸å…³æ€§åˆ†æ
        correlation = np.corrcoef(input_audio, output_audio)[0, 1]
        print(f"  ç›¸å…³ç³»æ•°: {correlation:.4f}")

        # é¢‘åŸŸåˆ†æï¼ˆç®€å•ï¼‰
        input_fft = np.fft.rfft(input_audio)
        output_fft = np.fft.rfft(output_audio)

        input_spectrum_energy = np.sum(np.abs(input_fft) ** 2)
        output_spectrum_energy = np.sum(np.abs(output_fft) ** 2)

        print(f"  è¾“å…¥é¢‘è°±èƒ½é‡: {input_spectrum_energy:.2e}")
        print(f"  è¾“å‡ºé¢‘è°±èƒ½é‡: {output_spectrum_energy:.2e}")

        # è´¨é‡æŒ‡æ ‡
        print(f"\nè´¨é‡æŒ‡æ ‡:")
        print(f"  âœ… è¾“å‡ºéŸ³é¢‘ç”ŸæˆæˆåŠŸ")
        print(f"  âœ… æ•°æ®æ ¼å¼æ­£ç¡®")
        print(f"  âœ… æ•°å€¼èŒƒå›´åˆç† ({np.min(output_audio):.3f} åˆ° {np.max(output_audio):.3f})")

        if correlation > 0.7:
            print(f"  âœ… ä¸è¾“å…¥ä¿æŒè‰¯å¥½ç›¸å…³æ€§ ({correlation:.3f})")
        else:
            print(f"  âš ï¸  ä¸è¾“å…¥ç›¸å…³æ€§è¾ƒä½ ({correlation:.3f})")

    def run(self):
        """è¿è¡Œæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ"""
        self.print_header("ç®€åŒ–ç‰ˆRVCæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨")

        try:
            # 1. æ£€æŸ¥æ–‡ä»¶
            self.check_files()

            # 2. åˆ›å»ºæˆ–åŠ è½½è¾“å…¥éŸ³é¢‘
            if os.path.exists(self.input_audio):
                print(f"\nå‘ç°è¾“å…¥éŸ³é¢‘æ–‡ä»¶: {self.input_audio}")
                try:
                    from scipy.io import wavfile
                    sample_rate, input_audio = wavfile.read(self.input_audio)
                    input_audio = input_audio.astype(np.float32) / 32768.0  # è½¬æ¢ä¸ºfloat32

                    # å¤„ç†ç«‹ä½“å£°è½¬å•å£°é“
                    if len(input_audio.shape) > 1 and input_audio.shape[1] > 1:
                        print(f"  æ£€æµ‹åˆ°ç«‹ä½“å£°éŸ³é¢‘ {input_audio.shape}ï¼Œè½¬æ¢ä¸ºå•å£°é“")
                        input_audio = np.mean(input_audio, axis=1)

                    print(f"âœ… åŠ è½½çœŸå®éŸ³é¢‘æ–‡ä»¶")
                    print(f"  å½¢çŠ¶: {input_audio.shape}")
                    print(f"  é‡‡æ ·ç‡: {sample_rate} Hz")
                except ImportError:
                    print("âš ï¸  scipyä¸å¯ç”¨ï¼Œä½¿ç”¨åˆæˆéŸ³é¢‘")
                    input_audio, sample_rate = self.create_synthetic_input()
                except Exception as e:
                    print(f"âš ï¸  åŠ è½½éŸ³é¢‘å¤±è´¥: {e}ï¼Œä½¿ç”¨åˆæˆéŸ³é¢‘")
                    input_audio, sample_rate = self.create_synthetic_input()
            else:
                print(f"\nè¾“å…¥éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºåˆæˆéŸ³é¢‘")
                input_audio, sample_rate = self.create_synthetic_input()

            # 3. æ‰§è¡Œæ¨¡æ‹Ÿæ¨ç†
            output_audio = self.simulate_rvc_inference(input_audio, sample_rate)

            # 4. ä¿å­˜è¾“å‡ºéŸ³é¢‘
            if not self.save_wav_simple(self.output_audio, output_audio, sample_rate):
                return False

            # 5. ç”Ÿæˆå…ƒæ•°æ®
            metadata = self.generate_test_metadata(input_audio, output_audio, sample_rate)

            # 6. åˆ›å»ºå¯¹æ¯”æŠ¥å‘Š
            self.create_comparison_report(input_audio, output_audio)

            # 7. æ€»ç»“
            self.print_header("ç”Ÿæˆå®Œæˆ")
            print(f"âœ… æµ‹è¯•ç”¨ä¾‹ç”ŸæˆæˆåŠŸ!")
            print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
            print(f"  ğŸ“„ å‚è€ƒè¾“å‡º: {self.output_audio}")
            print(f"  ğŸ“‹ å…ƒæ•°æ®: test_case_metadata.json")

            print(f"\nä¸‹ä¸€æ­¥:")
            print(f"  1. è¿è¡Œ Rust æµ‹è¯•: cd rvc-rs && cargo test --test model_inference_test")
            print(f"  2. æˆ–ä½¿ç”¨å®Œæ•´æµ‹è¯•è„šæœ¬: python run_model_test.py")

            return True

        except Exception as e:
            print(f"\nâŒ ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("RVC ç®€åŒ–æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨")
    print("é€‚ç”¨äºRustå®ç°éªŒè¯")
    print("=" * 60)

    generator = SimpleTestCaseGenerator()
    success = generator.run()

    if success:
        print(f"\nğŸ‰ æµ‹è¯•ç”¨ä¾‹ç”ŸæˆæˆåŠŸ!")
        sys.exit(0)
    else:
        print(f"\nğŸ’¥ æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥!")
        sys.exit(1)

if __name__ == "__main__":
    main()
